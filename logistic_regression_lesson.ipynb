{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88c54ec",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1e98a",
   "metadata": {},
   "source": [
    "## What is Logistic Regression?\n",
    "\n",
    "- Technically a regression algorithm (goal is to find the values for the coefficients that weight each input variable)\n",
    "\n",
    "- Used for predicting discrete outcomes (binomial and multinomial)\n",
    "\n",
    "- Because the prediction for the output is transformed using the logistic function, a non-linear function, it is a classification algorithm.\n",
    "\n",
    "- The output is a value between 0 and 1 that represents the probability of one class over the other.\n",
    "\n",
    "- Like linear regression, logistic regression works better when you remove attributes that are either unrelated to the output variable or correlated to other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93909da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  versicolor  virginica\n",
       "1           5.1          3.5           1.4          0.2           0          0\n",
       "2           4.9          3.0           1.4          0.2           0          0\n",
       "3           4.7          3.2           1.3          0.2           0          0\n",
       "4           4.6          3.1           1.5          0.2           0          0\n",
       "5           5.0          3.6           1.4          0.2           0          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "# we will have 2 different target variables \n",
    "dummies = pd.get_dummies(df['species'], drop_first=True)\n",
    "\n",
    "df = pd.concat([df, dummies], axis=1).drop(columns=['species'])\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68c9d1",
   "metadata": {},
   "source": [
    "## Train Validate Test\n",
    "\n",
    "- Now we'll do our train/validate/test split:\n",
    "\n",
    "- We will walk through the lesson aiming to predict versicolor.\n",
    "\n",
    "- We'll do exploration and train our model on the train data\n",
    "\n",
    "- We tune our model on validate, since it will be out-of-sample until we use it.\n",
    "\n",
    "- And keep the test nice and safe and separate, for our final out-of-sample dataset, to see how well our tuned model performs on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c1beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7abf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is versicolor predictor\n",
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(\n",
    "    df, target='versicolor', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series \n",
    "# with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['versicolor','virginica'])\n",
    "y_train = train.versicolor\n",
    "\n",
    "X_validate = validate.drop(columns=['versicolor','virginica'])\n",
    "y_validate = validate.versicolor\n",
    "\n",
    "X_test = test.drop(columns=['versicolor','virginica'])\n",
    "y_test = test.versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294df28",
   "metadata": {},
   "source": [
    "### We'll use the LogisticRegression class from the sklearn.linear_model module to implement our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8660af7c",
   "metadata": {},
   "source": [
    "# Model 1, make the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91288c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, class_weight={0:1, 1:99},\n",
    "                           random_state=123, intercept_scaling=1,\n",
    "                           solver='lbfgs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26e17c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={0: 1, 1: 99}, random_state=123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307262fd",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "\n",
    "Evaluate importance, or weight, of each feature, using the coefficients.\n",
    "\n",
    "Evaluate the intercept of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0a17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.45745489 -4.33000304  2.00440881 -2.79033335]]\n",
      "Intercept: \n",
      " [14.54733857]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe8fa1",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1a64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "735aa190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate probability\n",
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cba283d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.55\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf19e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 38]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4125f920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0   1\n",
       "versicolor        \n",
       "0           18  38\n",
       "1            0  28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crosstab\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56115a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.32      0.49        56\n",
      "           1       0.42      1.00      0.60        28\n",
      "\n",
      "    accuracy                           0.55        84\n",
      "   macro avg       0.71      0.66      0.54        84\n",
      "weighted avg       0.81      0.55      0.52        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ac6a0",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d94e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object\n",
    "logit2 = LogisticRegression(C=.1, class_weight={0:1, 1:99}, \n",
    "                            random_state=123, \n",
    "                            intercept_scaling=1,\n",
    "                            solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a27df549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={0: 1, 1: 99}, random_state=123)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "logit2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "557f6fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.20880009 -1.67727952  1.00954681 -0.25663236]]\n",
      "Intercept: \n",
      " [6.02992374]\n"
     ]
    }
   ],
   "source": [
    "# feature importance:\n",
    "# evaluate the coefficients to get the importance or weight of\n",
    "# each feature:\n",
    "\n",
    "print('Coefficient: \\n', logit2.coef_)\n",
    "print('Intercept: \\n', logit2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bec63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred2 = logit2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b89f1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the probability\n",
    "y_pred_proba2 = logit2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbd021a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.40\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f863034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 50]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "# create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de43f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.19        56\n",
      "           1       0.36      1.00      0.53        28\n",
      "\n",
      "    accuracy                           0.40        84\n",
      "   macro avg       0.68      0.55      0.36        84\n",
      "weighted avg       0.79      0.40      0.31        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a classification report\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe128c",
   "metadata": {},
   "source": [
    "# Validate Models\n",
    "### Evaluate on Out of Sample Data\n",
    "- Are either overfitting? Let's validate on unseen data, X_validate. This means we use logit & logit2 to predict on X_validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18bc1cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: solver = lbfgs, c = 1\n",
      "Accuracy: 0.53\n",
      "[[ 7 17]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.45        24\n",
      "           1       0.41      1.00      0.59        12\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.71      0.65      0.52        36\n",
      "weighted avg       0.80      0.53      0.50        36\n",
      "\n",
      "---------------------------------------------------------\n",
      "Model 2: solver = lbfgs, c = .1\n",
      "Accuracy: 0.33\n",
      "[[ 0 24]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.33      1.00      0.50        12\n",
      "\n",
      "    accuracy                           0.33        36\n",
      "   macro avg       0.17      0.50      0.25        36\n",
      "weighted avg       0.11      0.33      0.17        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "y_pred1 = logit.predict(X_validate)\n",
    "y_pred2 = logit2.predict(X_validate)\n",
    "\n",
    "\n",
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "# accuracy of model 1\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_validate, y_validate)))\n",
    "\n",
    "# confusion matrix of model 1\n",
    "print(confusion_matrix(y_validate, y_pred1))\n",
    "\n",
    "# classification report of model 1\n",
    "print(classification_report(y_validate, y_pred1))\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Model 2: solver = lbfgs, c = .1\")\n",
    "\n",
    "# accuracy of model 2\n",
    "print('Accuracy: {:.2f}'.format(logit2.score(X_validate, y_validate)))\n",
    "\n",
    "# confusion matrix of model 2\n",
    "print(confusion_matrix(y_validate, y_pred2))\n",
    "\n",
    "# classification report of model 2\n",
    "print(classification_report(y_validate, y_pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b167fb",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "### Using the best model, compute the accuracy of the model when run on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca3b9543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: solver = lbfgs, c = 1\n",
      "Accuracy: 0.47\n",
      "[[ 4 16]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        20\n",
      "           1       0.38      1.00      0.56        10\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.69      0.60      0.44        30\n",
      "weighted avg       0.79      0.47      0.41        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit.predict(X_test)\n",
    "y_pred_proba = logit.predict_proba(X_test)\n",
    "\n",
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_test, y_test)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b116ec9",
   "metadata": {},
   "source": [
    "### Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9da0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of probabilities of being versicolor (versicolor == 1)\n",
    "\n",
    "y_pred_proba = np.array([i[1] for i in y_pred_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73be91a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa60830f130>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# scatter plot where x is the probabilities and y is the class (0, 1)\n",
    "ax.scatter(y_pred_proba, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04244977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
